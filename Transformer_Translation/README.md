**Attention Is All You Need中文翻译**

本资源完整的翻译了论文，并且给出了论文中所有引用资料的网络连接，方便对Transformer感兴趣的朋友们进一步研究。

1. 原文 [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

   论文总共有五个版本：

   **[[v1]](https://arxiv.org/abs/1706.03762v1)** Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB)
   
   **[[v2]](https://arxiv.org/abs/1706.03762v2)** Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB)
   
   **[[v3]](https://arxiv.org/abs/1706.03762v3)** Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB)
   
   **[[v4]](https://arxiv.org/abs/1706.03762v4)** Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB)
   
   **[v5]** Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB)

   本文翻译是第五个版本。

2. 论文代码：https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py 。

3. 论文翻译 [PDF版下载]。

4. 推荐一个详细实现transformer的colab地址：

